{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e19bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook \n",
    "from model.resattnet import SelfPose as SelfPose\n",
    "from dataloader import XRegoDataset \n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import webdataset as wds\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "from webdataset.handlers import ignore_and_continue\n",
    "from mpl_toolkits.mplot3d import axes3d \n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e19072",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def transform(x):\n",
    "    x = x.decode(\"utf-8\").split(\",\")\n",
    "    x = np.array(x).astype(float).reshape(-1,3)\n",
    "    x = np.concatenate(( x[14:17], x[22:25]))\n",
    "\n",
    "    return x.reshape(-1)\n",
    "\n",
    "def image_preproc(x):\n",
    "    return preproc(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fffa7e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Plot Kinematic Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_chain_dots(\n",
    "        joints: np.ndarray,   # shape == (n_dots, 3)\n",
    "        chain_dots_indexes: tp.List[int], # length == n_dots_in_chain\n",
    "                                          # in continuous order, i.e. \n",
    "                                          # left_hand_ix >>> chest_ix >>> right_hand_ix\n",
    "        ) -> np.ndarray:    # chain of dots\n",
    "    return joints[chain_dots_indexes]\n",
    "\n",
    "\n",
    "def get_chains(\n",
    "        joints,   # shape == (n_dots, 3)\n",
    "        head: tp.List[int], # pelvis >>> chest >>> head\n",
    "        spine: tp.List[int], # left_leg >>> pelvis >>> right_leg\n",
    "        arm1: tp.List[int],\n",
    "        arm2,\n",
    "        neck,\n",
    "        right_leg,\n",
    "        left_leg,\n",
    "        ):\n",
    "    return (get_chain_dots(joints, head),\n",
    "            get_chain_dots(joints, spine),\n",
    "            get_chain_dots(joints, arm1),\n",
    "            get_chain_dots(joints, arm2),\n",
    "            get_chain_dots(joints, neck),\n",
    "            get_chain_dots(joints, right_leg),\n",
    "            get_chain_dots(joints, left_leg),\n",
    "            )\n",
    "\n",
    "\n",
    "def subplot_nodes(dots: np.ndarray, ax, size=20):\n",
    "    return ax.scatter3D(*dots.T, c=dots[:, -1], s=size)\n",
    "\n",
    "\n",
    "def subplot_bones(chains: tp.Tuple[np.ndarray, ...], ax):\n",
    "    return [ax.plot(*chain.T) for chain in chains]\n",
    "\n",
    "\n",
    "def plot_skeletons(skeletons, chains_ixs, err_size=20, std_size=20):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    sizes = [err_size, std_size]\n",
    "    labels = [\"Prediction: circle size=uncertainty\", \"GT: circle size=error\"]\n",
    "    for i, joints in enumerate(skeletons, start=1):\n",
    "        chains = get_chains(joints, *chains_ixs)\n",
    "        ax = fig.add_subplot(1, 2, i, projection='3d')\n",
    "        ax.set_xlabel(labels[i-1], fontsize=10, rotation=100)\n",
    "        subplot_nodes(joints, ax, sizes[i-1])\n",
    "        subplot_bones(chains, ax)\n",
    "    plt.show()\n",
    "    \n",
    "def plot(gt_pose, pred_pose, err_size=20, std_size=20):\n",
    "    # Kinematic Tree for visualization\n",
    "    # each list create bones between joints\n",
    "    chains_ixs = ([0],[1, 2, 3],[3, 4, 5, 6],[3, 7, 8, 9],[3, 10],[1, 11,12,13],[1, 14,15,16]) \n",
    "    plot_skeletons([gt_pose, pred_pose], chains_ixs, err_size, std_size)\n",
    " \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01006b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "def Gaussian(sigma):\n",
    "    if sigma == 7:\n",
    "        return np.array([1.23409802e-04, 1.50343915e-03, 6.73794700e-03, 1.11089963e-02,\n",
    "                     6.73794700e-03, 1.50343915e-03, 1.23409802e-04, 1.50343915e-03,\n",
    "                     1.83156393e-02, 8.20849985e-02, 1.35335281e-01, 8.20849985e-02,\n",
    "                     1.83156393e-02, 1.50343915e-03, 6.73794700e-03, 8.20849985e-02,\n",
    "                     3.67879450e-01, 6.06530666e-01, 3.67879450e-01, 8.20849985e-02,\n",
    "                     6.73794700e-03, 1.11089963e-02, 1.35335281e-01, 6.06530666e-01,\n",
    "                     1.00000000e+00, 6.06530666e-01, 1.35335281e-01, 1.11089963e-02,\n",
    "                     6.73794700e-03, 8.20849985e-02, 3.67879450e-01, 6.06530666e-01,\n",
    "                     3.67879450e-01, 8.20849985e-02, 6.73794700e-03, 1.50343915e-03,\n",
    "                     1.83156393e-02, 8.20849985e-02, 1.35335281e-01, 8.20849985e-02,\n",
    "                     1.83156393e-02, 1.50343915e-03, 1.23409802e-04, 1.50343915e-03,\n",
    "                     6.73794700e-03, 1.11089963e-02, 6.73794700e-03, 1.50343915e-03,\n",
    "                     1.23409802e-04]).reshape(7,7)\n",
    "    elif sigma == n:\n",
    "        return g_inp\n",
    "    else:\n",
    "        raise Exception('Gaussian {} Not Implement'.format(sigma))\n",
    "\n",
    "def DrawGaussian(img, pt, sigma):\n",
    "    tmpSize = int(np.math.ceil(3 * sigma))\n",
    "    ul = [int(np.math.floor(pt[0] - tmpSize)), int(np.math.floor(pt[1] - tmpSize))]\n",
    "    br = [int(np.math.floor(pt[0] + tmpSize)), int(np.math.floor(pt[1] + tmpSize))]\n",
    "\n",
    "    if ul[0] > img.shape[1] or ul[1] > img.shape[0] or br[0] < 1 or br[1] < 1:\n",
    "        return img\n",
    "\n",
    "    size = 2 * tmpSize + 1\n",
    "    g = Gaussian(size)\n",
    "    g_x = [max(0, -ul[0]), min(br[0], img.shape[1]) - max(0, ul[0]) + max(0, -ul[0])]\n",
    "    g_y = [max(0, -ul[1]), min(br[1], img.shape[0]) - max(0, ul[1]) + max(0, -ul[1])]\n",
    "\n",
    "    img_x = [max(0, ul[0]), min(br[0], img.shape[1])]\n",
    "    img_y = [max(0, ul[1]), min(br[1], img.shape[0])]\n",
    "\n",
    "    img[img_y[0]:img_y[1], img_x[0]:img_x[1]] = g[g_y[0]:g_y[1], g_x[0]:g_x[1]]\n",
    "    return img\n",
    "\n",
    "def get_heatmap(points, shape, new_shape=(51,51), joints=6):\n",
    "    height, width = shape[0], shape[1]\n",
    "    points[:, 0] = (points[:, 0] / width) * new_shape[1]\n",
    "    points[:, 1] = (points[:, 1] / height) * new_shape[0]\n",
    "    points = points.astype(int)\n",
    "    heatmaps = np.zeros((joints, new_shape[0], new_shape[1]))\n",
    "    for i in range(joints):\n",
    "        heatmaps[i] = DrawGaussian(heatmaps[i], (points[i][0], points[i][1]), 1)\n",
    "    return heatmaps\n",
    "\n",
    "\n",
    "\n",
    "def transform2D(x):\n",
    "    x = x.decode(\"utf-8\").split(\",\")\n",
    "    x = np.array(x).astype(float).reshape(-1,2)\n",
    "    x = np.concatenate((x[14:17], x[22:26]))\n",
    "    heatmaps = get_heatmap(x, (800, 1200))\n",
    "    return heatmaps\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669fecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f87abd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_url = glob.glob(\"/egopose-data/web-datasets/xr*train*tar\")\n",
    "\"/egopose-data/web\"\n",
    "# test_url = glob.glob(\"/egopose-data/web-datasets/mo2cap2_test/mo*train*tar\")\n",
    "test_url = glob.glob(\"/egopose-data/web-datasets/xr*test*\")\n",
    "print(len(test_url))\n",
    "ds = wds.WebDataset(train_url).decode(\"pil\").to_tuple(\"pose_image.png\", \"pose_image_depth.png\", \"pose_3dp.csv\", \"pose_2dp.csv\").map_tuple(image_preproc, image_preproc, transform, transform2D)\n",
    "train_loader = DataLoader(ds.batched(1), num_workers=1, batch_size=None)\n",
    "\n",
    "ds_test = wds.WebDataset(test_url).decode(\"pil\").shuffle(1000, initial=1000).to_tuple(\"pose_image.png\", \"pose_image_depth.png\", \"pose_3dp.csv\", \"pose_2dp.csv\",handler=ignore_and_continue).map_tuple(image_preproc, image_preproc, transform, transform2D)\n",
    "test_loader = DataLoader(ds_test, num_workers=8, batch_size=32)\n",
    " \n",
    "self_pose = SelfPose()\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": test_loader}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "self_pose.load_state_dict(torch.load(\"./ckpts/resattnet/14_epoch_1.1127434143256608e-05.pth\"))\n",
    "self_pose.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imgs = []\n",
    "# for im,_, _, _ in train_loader:\n",
    "#     im = np.transpose(im.cpu().numpy()[0], (1,2,0))\n",
    "#     im = cv2.resize(im, (500,368)) * 255\n",
    "#     im = im.astype(\"uint8\")\n",
    "#     imgs.append(im)\n",
    "#     plt.imshow(im)\n",
    "#     plt.show()\n",
    "#     break\n",
    "# len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14586233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blur =  iaa.Sequential(\n",
    "\n",
    "#                  iaa.OneOf([\n",
    "#                     iaa.GaussianBlur((3, 5.0)), # blur images with a sigma between 0 and 3.0\n",
    "#                     iaa.AverageBlur(k=(4, 9)), # blur image using local means with kernel sizes between 2 and 7\n",
    "#                     iaa.MedianBlur(k=(5, 9)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "#                 ]) )\n",
    "# contrast =iaa.LinearContrast((0.5, 2.0), per_channel=0.5)\n",
    "# hue_sat = iaa.AddToHueAndSaturation()\n",
    "\n",
    "# do= iaa.OneOf([\n",
    "#                     iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "#                     iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "#                 ])\n",
    "# simp = iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "#                     iaa.EdgeDetect(alpha=(0.2, 0.6)),iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0))]))\n",
    "\n",
    "\n",
    "                   \n",
    "# dos = do(images= imgs)\n",
    "# cons = contrast(images= imgs)\n",
    "# hues = hue_sat(images= imgs)\n",
    "# blurs = blur(images= imgs)\n",
    "# sims = simp(images = imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c050f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for im in sims:\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(im)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a7e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_error(pred, gt):\n",
    "    pred = pred.reshape((-1, 6, 3))\n",
    "    gt = gt.reshape((-1, 6, 3))\n",
    "    error = np.sqrt(np.sum((pred-gt) ** 2, axis=2))\n",
    "    return error\n",
    "\n",
    "def inference(models):\n",
    "    results = []\n",
    "    for model in models:\n",
    "        model.eval()   # Set model to evaluate mode\n",
    "    phase=\"val\"\n",
    "    errors = []\n",
    "    count = 0\n",
    "    try:\n",
    "        for inputs,_, labels,hm in dataloaders[\"val\"]: \n",
    "            inputs = inputs.to(device).float()\n",
    "#             hm = np.sum(hm[0].numpy(), 0)\n",
    "#             plt.imshow(hm)\n",
    "#             plt.show()\n",
    "            count += inputs.shape[0]\n",
    "#             print(\"before\")\n",
    "            results, hm, hm_pred = infer_multiple(models[0], inputs)#\n",
    "#             print(\"what\")\n",
    "            results = results.cpu().detach().numpy()\n",
    "#             print(\"a\")\n",
    "#             hm = np.sum(hm[0].cpu().detach().numpy(), 0)\n",
    "#             print(hm.shape)\n",
    "#             hm = hm[0].cpu().detach().numpy()[3]\n",
    "#             hm_pred = np.sum(hm_pred[0].cpu().detach().numpy(), 0)\n",
    "#             print(\"hain\")\n",
    "#             print(hm.shape)\n",
    "#             print(np.mean(hm), np.max(hm))\n",
    "#             hm[hm<0.01] = 0\n",
    "#             plt.imshow(hm)\n",
    "#             plt.show()\n",
    "#             fig, axs = plt.subplots(2, 2)\n",
    "            \n",
    "#             axs[0, 0].imshow(hm)\n",
    "#             axs[0, 0].set_title('Axis [0, 0]')\n",
    "#             axs[0, 1].imshow(hm_pred)\n",
    "#             axs[0, 1].set_title('Axis [0, 1]')\n",
    "#             axs[1, 0].imshow(hm_pred)\n",
    "#             axs[1, 0].set_title('Axis [1, 0]')\n",
    "#             axs[1, 1].imshow(hm)\n",
    "#             axs[1, 1].set_title('Axis [1, 1]')\n",
    "            \n",
    "            labels = labels.reshape(-1, 6, 3).cpu().numpy() # 17 joints for visualizatoin\n",
    "            error = calculate_error(results, labels) # 4-10 are both arm joints\n",
    "            err = np.mean(error)\n",
    "            print( \"count: \", count, \"err\", err)\n",
    "            yield results, labels, error\n",
    "    except Exception as e:\n",
    "        print(\"\\n\\n\\nException as e:\", e)\n",
    "        return\n",
    "            \n",
    "\n",
    "def plot_inference(model, plot_max=5):\n",
    "    for i, (outputs, labels, error) in enumerate(inference(model)):\n",
    "        pred = labels.copy()\n",
    "        pred[:, 4:10] = outputs[0] # replace orignal arm joints with predicted arm joints in kinematic tree\n",
    "        plot(pred[0], labels[0]) #plot first prediction in batch\n",
    "        if (i+1) >= plot_max:\n",
    "            break\n",
    "            \n",
    "def mean_error(model, total_batches=float(\"inf\")):\n",
    "    errors = []\n",
    "    results = [[] for i in range(21)]\n",
    "    gts = []\n",
    "    for i, (outputs, gt, error) in enumerate(inference(model)):\n",
    "\n",
    "        errors.extend(error)\n",
    "        gts.extend(gt)\n",
    "#         for j in range(len(outputs)):\n",
    "#             results[j].extend(outputs[j])\n",
    "        if i == total_batches:\n",
    "            break\n",
    "    print(f\"Mean Error of all batches: {np.mean(errors)*10} millimeters \")\n",
    "    return results, gts, errors\n",
    "\n",
    "def infer_multiple(model: list, inputs):\n",
    "    results = []\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs, hm, pred_hm,_, _= model(inputs)\n",
    "#         outputs = model(inputs)\n",
    "#         print(outputs.shape, hm.shape, pred_hm.shape)\n",
    "#         outputs = [o.view(-1, 6, 3).cpu().numpy() * 2000 for o in outputs]# both arms \n",
    "        return outputs * 300, hm, pred_hm\n",
    "#         return outputs * 300, \"\", \"\"\n",
    "    \n",
    "\n",
    "results, gts, errors = mean_error([self_pose], 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7403cb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np_errors = np.stack(errors)\n",
    "# np.save(\"resnset18.npy\", np_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775be900",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean(np_errors, 0) * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af06d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "array([ 35.25950946,  55.16844587, 103.40663034,  30.61601325,\n",
    "        47.45479543,  93.35602984]) \n",
    "# VAE\n",
    "\n",
    "array([28.07453525, 52.11339807, 99.06696299, 29.21238883, 48.14259912,\n",
    "       89.86875672])\n",
    "# AE\n",
    "\n",
    "array([25.46017313, 40.54446942, 65.40962568, 21.48813598, 34.28043555,\n",
    "       65.77914521])\n",
    "\n",
    "42.23 + 59.53 + 110.44 + 37.42 + 52.90 + 99.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "28.07 & 52.11 & 99.06 & 29.21 & 48.14 & 89.86 \n",
    " 35.25 &  55.16 103.40  & 30.61 & 47.45& 93.35\n",
    "25.46 & 40.54 & 65.40 & 21.48 & 34.28 &65.77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200ea52",
   "metadata": {},
   "source": [
    "# VAE uncertainty\n",
    "\n",
    "Average standard deviation of each joint for 10 random points per image\n",
    "                    x(mm)       y(mm)       z(mm)\n",
    " Left Shoulder      0.08918472  0.09157255  0.0698511 \n",
    " Left Elbow         0.11902293  0.12438361  0.127807\n",
    " Left Hand          0.15035595, 0.15886429, 0.16023856\n",
    " Right Shoulder     0.07806852, 0.08045479, 0.05805141\n",
    " Right Elbow        0.09848355, 0.10558292, 0.09553152\n",
    " Right Hand         0.14335191, 0.16634406, 0.15219972"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c2fa4",
   "metadata": {},
   "source": [
    "# 5 Model uncertainty\n",
    "Average standard deviation of each joint for 5 models trained from random initialization\n",
    "                    x(mm)       y(mm)       z(mm)\n",
    " Left Shoulder      0.77400464, 0.9956709 , 0.6167278 \n",
    " Left Elbow         1.3933133 , 1.9136935 , 1.6917565\n",
    " Left Hand          2.4741955 , 2.9097495 , 3.5901506\n",
    " Right Shoulder     0.86049104, 1.019562  , 0.6316848\n",
    " Right Elbow        1.3152746 , 1.8138525 , 1.3953665\n",
    " Right Hand         2.0660796 , 2.756212  , 2.9830382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e25aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5651e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
